ğŸ§¬ GeneCell3: Multi-Label Protein Function Prediction
This project focuses on predicting protein functions (specifically cellular components) using multi-label deep learning models. The data is sourced from UniProt, a leading protein sequence and functional information database.

We developed two models:

ğŸ§ª Base Model â€“ uses only protein sequences.

ğŸŒ Enhanced Model â€“ uses both sequences and subcellular location descriptions.

ğŸ“ Dataset
The dataset was manually curated from UniProt and contains the following features:

Sequence: Amino acid sequence of the protein.

Subcellular location [CC]: Natural language description of where the protein is located in the cell.

Gene Ontology (cellular component): Target labels (multi-label) indicating where the protein functions within a cell.

ğŸ§¼ Preprocessing Steps
Reproducibility: Set random seeds for consistency.

Sequence Cleaning: Standardize amino acid sequences and replace invalid characters.

Sequence Encoding: Label encode and pad sequences.

Location Processing: Clean natural language text using regex.

TF-IDF Vectorization: Turn location descriptions into numeric features.

Label Encoding: Convert GO terms to binary vectors using MultiLabelBinarizer.

ğŸ§  Models
ğŸ”¹ Base Model
Input: Amino acid sequence

Architecture:

Embedding â†’ BiLSTM â†’ Conv1D â†’ BiLSTM â†’ Dense

Output: Multi-label sigmoid classifier

ğŸ”¸ Enhanced Model
Inputs: Amino acid sequence + TF-IDF vector of subcellular location

Architecture:

Embedding â†’ BiLSTM â†’ Attention â†’ GlobalMaxPool

Dense layers on location input

Concatenate â†’ Dense â†’ Output

âš™ï¸ Training Details
Loss: Binary Crossentropy

Optimizer: Adam with gradient clipping

Class imbalance: Handled using class weights

Early stopping and learning rate reduction on plateau

ğŸ“Š Evaluation Metrics
Metric	Base Model	Enhanced Model
Exact Match Ratio	0.00%	0.00%
Hamming Loss	0.3824	0.2273
F1 Micro	2.44%	2.74%
F1 Macro	1.61%	2.42%
Jaccard Score	1.99%	1.70%
Note: Protein function prediction is a complex task, especially with sparse and overlapping multi-labels. The enhanced model still shows a consistent improvement across most metrics.

ğŸ§  Interpretation Guide
Hamming Loss: Lower is better â€” how many labels were incorrectly predicted.

F1 Micro: Weighted average, good for class imbalance.

F1 Macro: Treats all classes equally â€” lower for imbalanced data.

Jaccard Score: Measures overlap between prediction and true labels.

Exact Match Ratio: How often the entire label set was predicted correctly (very strict).

ğŸ“š How to Run
Install dependencies:

bash
Copy
Edit
pip install -r requirements.txt
Add your dataset as Small_Data.xlsx.

Run the notebook or script containing the model training code.

ğŸ” Licensing and Credits
Dataset Source: UniProt

This project is intended for educational and research purposes only.
